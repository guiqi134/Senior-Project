{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 2095, 0: 2091, -1: 2032})\n",
      "Counter({1: 2095, 0: 2091, -1: 2032})\n",
      "(4144, 17967)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import xlwings as xw\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "def build_dataset(labels, FV):\n",
    "    result = collections.Counter(labels)\n",
    "    print(result)\n",
    "    ratings = list(result.keys())\n",
    "    counts = list(result.values())\n",
    "    X_train = np.ones((1, FV.shape[1]))\n",
    "    X_test = np.ones((1, FV.shape[1]))\n",
    "    Y_train = np.ones((1,1))\n",
    "    Y_test = np.ones((1,1))\n",
    "    labels = labels.reshape(-1,1)\n",
    "    arr_index = -1\n",
    "\n",
    "    for i in range(0, len(counts)):\n",
    "        num_train = int(counts[i]*2/3)\n",
    "        num_test = counts[i] - num_train\n",
    "        X_train = vstack([X_train, FV[arr_index+1:arr_index+num_train+1][:]]).toarray()\n",
    "        Y_train = np.concatenate((Y_train, labels[arr_index+1:arr_index+num_train+1]), axis=0)\n",
    "        arr_index += num_train\n",
    "        X_test = vstack([X_test, FV[arr_index+1:arr_index+num_test+1][:]]).toarray()\n",
    "        Y_test = np.concatenate((Y_test, labels[arr_index+1:arr_index+num_test+1]), axis=0)\n",
    "        arr_index += num_test\n",
    "\n",
    "    X_train = X_train[1:][:]\n",
    "    X_test = X_test[1:][:]\n",
    "    Y_train = Y_train[1:][:]\n",
    "    Y_test = Y_test[1:][:]\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "corpus = list(pd.read_excel('train_set_2.xlsx')['Segement'].values)\n",
    "# labels_1 = pd.read_excel('train_set_2.xlsx')['Label_1'].values # array type\n",
    "labels_2 = pd.read_excel('train_set_2.xlsx')['Label_2'].values # array type\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "word = vectorizer.get_feature_names()\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "# get tfidf feature matrix\n",
    "tfidf = transformer.fit_transform(X)\n",
    "\n",
    "# get LIWC feature matrix and normalize\n",
    "wb = xw.Book('train_set_2.xlsx')\n",
    "sht = wb.sheets['dataset']\n",
    "rng = sht.range('D2').expand('table')\n",
    "arr_feature = np.asarray(rng.value)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(arr_feature)\n",
    "LIWC = scaler.transform(arr_feature)\n",
    "\n",
    "# build tfidf + 3 class dataset \n",
    "X_train1, X_test1, Y_train1, Y_test1 = build_dataset(labels_2, tfidf)\n",
    "\n",
    "# build tfidf + regression dataset\n",
    "# X_train2, X_test2, Y_train2, Y_test2 = build_dataset(labels_1, tfidf)\n",
    "\n",
    "# build LIWC + 3 classes dataset \n",
    "X_train3, X_test3, Y_train3, Y_test3 = build_dataset(labels_2, LIWC)\n",
    "\n",
    "# build LIWC + regression dataset \n",
    "# X_train4, X_test4, Y_train4, Y_test4 = build_dataset(labels_1, LIWC)\n",
    "\n",
    "print(X_train1.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1 MA: 0.8379942140790743\n",
      "model_1 conf:\n",
      " [[537  83  58]\n",
      " [ 91 525  81]\n",
      " [  9  14 676]]\n",
      "\n",
      "model_3 MA: 0.6779170684667309\n",
      "model_3 conf:\n",
      " [[402 232  44]\n",
      " [113 526  58]\n",
      " [ 59 162 478]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# train model_1 -- tfidf + NB\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train1, Y_train1.flatten())\n",
    "\n",
    "# train model_2 -- regression \n",
    "# reg1 = LinearRegression().fit(X_train2, Y_train2.flatten())\n",
    "\n",
    "# train model_3 -- LIWC + NB\n",
    "clf2 = MultinomialNB()\n",
    "clf2.fit(X_train3, Y_train3.flatten())\n",
    "\n",
    "# train model_4 -- LIWC + regression\n",
    "# reg2 = LinearRegression().fit(X_train4, Y_train4.flatten())\n",
    "\n",
    "\n",
    "def cal_conf(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred, labels=[-1, 0, 1])\n",
    "\n",
    "MA1 = clf1.score(X_test1, Y_test1.flatten())\n",
    "predicts1 = clf1.predict(X_test1)\n",
    "conf1 = cal_conf(Y_test1, predicts1)\n",
    "print('model_1 MA:', MA1)\n",
    "print('model_1 conf:\\n', conf1)\n",
    "\n",
    "# MSE1 = mean_squared_error(Y_test2, reg1.predict(X_test2))\n",
    "# print('\\nmodel_2 MSE:', MSE1)\n",
    "\n",
    "MA2 = clf2.score(X_test3, Y_test3.flatten())\n",
    "predicts2 = clf2.predict(X_test3)\n",
    "conf2 = cal_conf(Y_test3, predicts2)\n",
    "print('\\nmodel_3 MA:', MA2)\n",
    "print('model_3 conf:\\n', conf2)\n",
    "\n",
    "# MSE2 = mean_squared_error(Y_test4, reg2.predict(X_test4))\n",
    "# print('\\nmodel_4 MSE:', MSE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape for X1:  (6218, 100)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d88bd63b3b71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0msvd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0msvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mX1_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The shape for X1: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX1_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtransformer\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \"\"\"\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 raise ValueError(\"n_components must be < n_features;\"\n\u001b[0;32m    177\u001b[0m                                  \" got %d >= %d\" % (k, n_features))\n\u001b[1;32m--> 178\u001b[1;33m             U, Sigma, VT = randomized_svd(X, self.n_components,\n\u001b[0m\u001b[0;32m    179\u001b[0m                                           \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                                           random_state=random_state)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36mrandomized_svd\u001b[1;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m     Q = randomized_range_finder(M, n_random, n_iter,\n\u001b[0m\u001b[0;32m    348\u001b[0m                                 power_iteration_normalizer, random_state)\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36mrandomized_range_finder\u001b[1;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'LU'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m             \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermute_l\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpower_iteration_normalizer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'QR'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# construct different dimension reducation result by PCA\n",
    "X1 = np.concatenate((X_train1, X_test1), axis=0)\n",
    "Y1 = np.concatenate((Y_train1, Y_test1), axis=0)\n",
    "n_features = min(X1.shape[0], X1.shape[1])\n",
    "n_components = np.arange(100, n_features, 500)  # options for n_components\n",
    "\n",
    "X1s = []\n",
    "for n in n_components:\n",
    "    svd = TruncatedSVD(n, n_iter=5)\n",
    "    svd.fit(X1)\n",
    "    X1_temp = svd.transform(X1)\n",
    "    print('The shape for X1: ', X1_temp.shape)\n",
    "    X1s.append([X1_temp, Y1.flatten()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:   42.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on dataset (6218, 100): \n",
      "\n",
      "{'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on dataset:\n",
      "\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.558 (+/-0.090) for {'C': 0.01, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.029) for {'C': 0.01, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.358 (+/-0.012) for {'C': 0.01, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.673 (+/-0.120) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.738 (+/-0.108) for {'C': 0.1, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.685 (+/-0.052) for {'C': 0.1, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.385 (+/-0.019) for {'C': 0.1, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.667 (+/-0.128) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.744 (+/-0.119) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.790 (+/-0.100) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.072) for {'C': 1.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.597 (+/-0.088) for {'C': 1.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.746 (+/-0.118) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.788 (+/-0.101) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.800 (+/-0.103) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.789 (+/-0.073) for {'C': 10.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.609 (+/-0.087) for {'C': 10.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.787 (+/-0.103) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.794 (+/-0.097) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.795 (+/-0.107) for {'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.774 (+/-0.069) for {'C': 100.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.603 (+/-0.092) for {'C': 100.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.502 (+/-0.105) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.721 (+/-0.120) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.776 (+/-0.112) for {'C': 1.0, 'kernel': 'linear'}\n",
      "0.790 (+/-0.101) for {'C': 10.0, 'kernel': 'linear'}\n",
      "0.792 (+/-0.098) for {'C': 100.0, 'kernel': 'linear'}\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:  9.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on dataset (6218, 600): \n",
      "\n",
      "{'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on dataset:\n",
      "\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.549 (+/-0.097) for {'C': 0.01, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.006) for {'C': 0.01, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.688 (+/-0.116) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.754 (+/-0.107) for {'C': 0.1, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.483 (+/-0.122) for {'C': 0.1, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.346 (+/-0.007) for {'C': 0.1, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.674 (+/-0.127) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.776 (+/-0.114) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.823 (+/-0.098) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.741 (+/-0.128) for {'C': 1.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.499 (+/-0.070) for {'C': 1.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.779 (+/-0.114) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.814 (+/-0.100) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.803 (+/-0.091) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.744 (+/-0.101) for {'C': 10.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.502 (+/-0.073) for {'C': 10.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.812 (+/-0.097) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.796 (+/-0.093) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.077) for {'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.725 (+/-0.103) for {'C': 100.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.501 (+/-0.072) for {'C': 100.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.502 (+/-0.105) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.743 (+/-0.122) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.813 (+/-0.104) for {'C': 1.0, 'kernel': 'linear'}\n",
      "0.801 (+/-0.089) for {'C': 10.0, 'kernel': 'linear'}\n",
      "0.776 (+/-0.097) for {'C': 100.0, 'kernel': 'linear'}\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed: 19.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on dataset (6218, 1100): \n",
      "\n",
      "{'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on dataset:\n",
      "\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.518 (+/-0.094) for {'C': 0.01, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.674 (+/-0.118) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.733 (+/-0.111) for {'C': 0.1, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.378 (+/-0.030) for {'C': 0.1, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.344 (+/-0.006) for {'C': 0.1, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.674 (+/-0.128) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.782 (+/-0.117) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.822 (+/-0.098) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.624 (+/-0.101) for {'C': 1.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.494 (+/-0.074) for {'C': 1.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.120) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.808 (+/-0.092) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.806 (+/-0.084) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.661 (+/-0.113) for {'C': 10.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.496 (+/-0.073) for {'C': 10.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.807 (+/-0.093) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.076) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.793 (+/-0.083) for {'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.661 (+/-0.113) for {'C': 100.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.496 (+/-0.073) for {'C': 100.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.502 (+/-0.106) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.745 (+/-0.121) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.808 (+/-0.094) for {'C': 1.0, 'kernel': 'linear'}\n",
      "0.788 (+/-0.081) for {'C': 10.0, 'kernel': 'linear'}\n",
      "0.766 (+/-0.072) for {'C': 100.0, 'kernel': 'linear'}\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed: 28.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on dataset (6218, 1600): \n",
      "\n",
      "{'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on dataset:\n",
      "\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.510 (+/-0.109) for {'C': 0.01, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.674 (+/-0.119) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.713 (+/-0.110) for {'C': 0.1, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.371 (+/-0.028) for {'C': 0.1, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.344 (+/-0.006) for {'C': 0.1, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.674 (+/-0.130) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.780 (+/-0.118) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.822 (+/-0.100) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.589 (+/-0.098) for {'C': 1.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.492 (+/-0.073) for {'C': 1.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.787 (+/-0.117) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.814 (+/-0.098) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.815 (+/-0.076) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.601 (+/-0.098) for {'C': 10.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.494 (+/-0.073) for {'C': 10.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.808 (+/-0.099) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.076) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.814 (+/-0.076) for {'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.601 (+/-0.098) for {'C': 100.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.494 (+/-0.073) for {'C': 100.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.502 (+/-0.106) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.745 (+/-0.121) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.817 (+/-0.104) for {'C': 1.0, 'kernel': 'linear'}\n",
      "0.789 (+/-0.082) for {'C': 10.0, 'kernel': 'linear'}\n",
      "0.763 (+/-0.079) for {'C': 100.0, 'kernel': 'linear'}\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed: 46.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on dataset (6218, 2100): \n",
      "\n",
      "{'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on dataset:\n",
      "\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.520 (+/-0.130) for {'C': 0.01, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.670 (+/-0.118) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.694 (+/-0.110) for {'C': 0.1, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.368 (+/-0.027) for {'C': 0.1, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.345 (+/-0.007) for {'C': 0.1, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.674 (+/-0.128) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.778 (+/-0.116) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.823 (+/-0.096) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.584 (+/-0.097) for {'C': 1.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.491 (+/-0.073) for {'C': 1.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.787 (+/-0.119) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.812 (+/-0.093) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.819 (+/-0.086) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.592 (+/-0.097) for {'C': 10.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.492 (+/-0.072) for {'C': 10.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.805 (+/-0.098) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.786 (+/-0.080) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.819 (+/-0.086) for {'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.592 (+/-0.097) for {'C': 100.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.492 (+/-0.072) for {'C': 100.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.502 (+/-0.106) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.745 (+/-0.119) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.813 (+/-0.096) for {'C': 1.0, 'kernel': 'linear'}\n",
      "0.779 (+/-0.080) for {'C': 10.0, 'kernel': 'linear'}\n",
      "0.765 (+/-0.084) for {'C': 100.0, 'kernel': 'linear'}\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed: 55.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on dataset (6218, 2600): \n",
      "\n",
      "{'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on dataset:\n",
      "\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.527 (+/-0.140) for {'C': 0.01, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.667 (+/-0.118) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.678 (+/-0.111) for {'C': 0.1, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.366 (+/-0.027) for {'C': 0.1, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.345 (+/-0.007) for {'C': 0.1, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.674 (+/-0.128) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.777 (+/-0.118) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.822 (+/-0.097) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.582 (+/-0.100) for {'C': 1.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.490 (+/-0.073) for {'C': 1.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.785 (+/-0.114) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.814 (+/-0.089) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.822 (+/-0.093) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.589 (+/-0.100) for {'C': 10.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.491 (+/-0.073) for {'C': 10.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.808 (+/-0.092) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.789 (+/-0.085) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.821 (+/-0.095) for {'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.589 (+/-0.100) for {'C': 100.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.491 (+/-0.073) for {'C': 100.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.502 (+/-0.106) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.745 (+/-0.121) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.819 (+/-0.094) for {'C': 1.0, 'kernel': 'linear'}\n",
      "0.781 (+/-0.086) for {'C': 10.0, 'kernel': 'linear'}\n",
      "0.769 (+/-0.087) for {'C': 100.0, 'kernel': 'linear'}\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed: 63.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on dataset (6218, 3100): \n",
      "\n",
      "{'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on dataset:\n",
      "\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.533 (+/-0.147) for {'C': 0.01, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.01, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.337 (+/-0.000) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.664 (+/-0.117) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.663 (+/-0.111) for {'C': 0.1, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.365 (+/-0.026) for {'C': 0.1, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.345 (+/-0.007) for {'C': 0.1, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.674 (+/-0.128) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.775 (+/-0.116) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.823 (+/-0.102) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.567 (+/-0.094) for {'C': 1.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.489 (+/-0.074) for {'C': 1.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.785 (+/-0.116) for {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.820 (+/-0.088) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.826 (+/-0.096) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.574 (+/-0.093) for {'C': 10.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.491 (+/-0.073) for {'C': 10.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.814 (+/-0.091) for {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.798 (+/-0.082) for {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.824 (+/-0.096) for {'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.574 (+/-0.093) for {'C': 100.0, 'gamma': 10.0, 'kernel': 'rbf'}\n",
      "0.491 (+/-0.073) for {'C': 100.0, 'gamma': 100.0, 'kernel': 'rbf'}\n",
      "0.502 (+/-0.106) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.744 (+/-0.121) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.825 (+/-0.096) for {'C': 1.0, 'kernel': 'linear'}\n",
      "0.784 (+/-0.084) for {'C': 10.0, 'kernel': 'linear'}\n",
      "0.768 (+/-0.082) for {'C': 100.0, 'kernel': 'linear'}\n",
      "\n",
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6832305cad9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters set found on dataset {0}: \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    680\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    683\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "score = 'accuracy'\n",
    "D = 'tfidf'\n",
    "datasets = []\n",
    "\n",
    "if D == 'tfidf':\n",
    "    datasets = X1s\n",
    "    C_range = np.logspace(-2, 2, 5)\n",
    "    gamma_range = np.logspace(-2, 2, 5)\n",
    "    cv = 5\n",
    "else:\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "    C_range = np.logspace(-2, 5, 8)\n",
    "    gamma_range = np.logspace(-5, 2, 8)\n",
    "    X3 = np.concatenate((X_train3, X_test3), axis=0)\n",
    "    Y3 = np.concatenate((Y_train3, Y_test3), axis=0)\n",
    "    datasets.append([X3, Y3.flatten()])\n",
    "    \n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma_range,\n",
    "                     'C': C_range},\n",
    "                    {'kernel': ['linear'], 'C': C_range}]\n",
    "svd_svm_scores = []\n",
    "svd_svm_params = []\n",
    "\n",
    "# train for dataset 1 and 3\n",
    "for dataset in datasets:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    \n",
    "    grid = GridSearchCV(SVC(), tuned_parameters, scoring=score, cv=cv, n_jobs=8, verbose=1)\n",
    "    grid.fit(dataset[0], dataset[1])\n",
    "\n",
    "    print(\"Best parameters set found on dataset {0}: \".format(dataset[0].shape))\n",
    "    print()\n",
    "    print(grid.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on dataset:\")\n",
    "    print()\n",
    "    means = grid.cv_results_['mean_test_score']\n",
    "    stds = grid.cv_results_['std_test_score']\n",
    "    svd_svm_scores.append(np.amax(means))\n",
    "    svd_svm_params.append(grid.best_params_)\n",
    "    for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "if D == 'tfidf':\n",
    "    n_components_svd = n_components[np.argmax(svd_svm_scores)]\n",
    "    params = svd_svm_params[np.argmax(svd_svm_scores)]\n",
    "    acc = max(svd_svm_scores)\n",
    "    print(\"best n_components by SVD CV = {0}, and its params = {1}, its acc. = {2}\".format(n_components_svd, params, acc))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(n_components, svd_svm_scores, 'b', label='SVD scores')\n",
    "    plt.axvline(n_components_svd, color='b',\n",
    "                label='SVD CV: %d' % n_components_svd, linestyle='--')\n",
    "    plt.xlabel('nb of components')\n",
    "    plt.ylabel('CV scores')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('TFIDF SVD different dimensions cv scores for D2')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed: 55.6min\n",
      "[Parallel(n_jobs=16)]: Done  60 out of  60 | elapsed: 107.2min finished\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-18f3930bbf81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters set found on dataset {0}: \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "score = 'accuracy'\n",
    "C_range = np.logspace(0, 1, 2)\n",
    "gamma_range = np.logspace(-1, 0, 2)\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma_range,\n",
    "                     'C': C_range},\n",
    "                    {'kernel': ['linear'], 'C': C_range}]\n",
    "\n",
    "print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "print()\n",
    "\n",
    "grid = GridSearchCV(SVC(), tuned_parameters, scoring=score, cv=cv, n_jobs=16, verbose=1)\n",
    "grid.fit(X1, Y1.flatten())\n",
    "\n",
    "print(\"Best parameters set found on dataset {0}: \".format(dataset[0].shape))\n",
    "print()\n",
    "print(grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on dataset:\")\n",
    "print()\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "full_max = np.amax(means)\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on dataset (6218, 17967): \n",
      "\n",
      "{'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on dataset:\n",
      "\n",
      "0.782 (+/-0.017) for {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.838 (+/-0.017) for {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.836 (+/-0.015) for {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.840 (+/-0.017) for {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.837 (+/-0.018) for {'C': 1.0, 'kernel': 'linear'}\n",
      "0.819 (+/-0.016) for {'C': 10.0, 'kernel': 'linear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on dataset {0}: \".format(X1.shape))\n",
    "print()\n",
    "print(grid.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on dataset:\")\n",
    "print()\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "full_max = np.amax(means)\n",
    "for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svd_svm_scores = [0.800, 0.823, 0.822, 0.822, 0.823, 0.822, 0.826]\n",
    "\n",
    "n_components_svd = n_components[np.argmax(svd_svm_scores)]\n",
    "# params = svd_svm_params[np.argmax(svd_svm_scores)]\n",
    "acc = max(svd_svm_scores)\n",
    "# print(\"best n_components by SVD CV = {0}, and its params = {1}, its acc. = {2}\".format(n_components_svd, params, acc))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(n_components[:7], svd_svm_scores, 'b', label='SVD scores')\n",
    "plt.axvline(n_components_svd, color='b',\n",
    "            label='SVD CV: %d' % n_components_svd, linestyle='--')\n",
    "plt.axhline(full_max, color='r',\n",
    "            label='SVD full CV: %d' % X1.shape[1], linestyle='--')\n",
    "plt.xlabel('nb of components')\n",
    "plt.ylabel('CV scores')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('TFIDF SVD different dimensions cv scores for D2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
