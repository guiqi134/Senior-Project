{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 930, 0: 930, -1: 930})\n",
      "Counter({1: 930, 0: 930, -1: 930})\n",
      "(1860, 11154)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import xlwings as xw\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def build_dataset(labels, FV):\n",
    "    result = collections.Counter(labels)\n",
    "    print(result)\n",
    "    ratings = list(result.keys())\n",
    "    counts = list(result.values())\n",
    "    X_train = np.ones((1, FV.shape[1]))\n",
    "    X_test = np.ones((1, FV.shape[1]))\n",
    "    Y_train = np.ones((1,1))\n",
    "    Y_test = np.ones((1,1))\n",
    "    labels = labels.reshape(-1,1)\n",
    "    arr_index = -1\n",
    "\n",
    "    for i in range(0, len(counts)):\n",
    "        num_train = int(counts[i]*2/3)\n",
    "        num_test = counts[i] - num_train\n",
    "        X_train = vstack([X_train, FV[arr_index+1:arr_index+num_train+1][:]]).toarray()\n",
    "        Y_train = np.concatenate((Y_train, labels[arr_index+1:arr_index+num_train+1]), axis=0)\n",
    "        arr_index += num_train\n",
    "        X_test = vstack([X_test, FV[arr_index+1:arr_index+num_test+1][:]]).toarray()\n",
    "        Y_test = np.concatenate((Y_test, labels[arr_index+1:arr_index+num_test+1]), axis=0)\n",
    "        arr_index += num_test\n",
    "\n",
    "    X_train = X_train[1:][:]\n",
    "    X_test = X_test[1:][:]\n",
    "    Y_train = Y_train[1:][:]\n",
    "    Y_test = Y_test[1:][:]\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "corpus = list(pd.read_excel('train_set_2.xlsx')['Segement'].values)\n",
    "# labels_1 = pd.read_excel('train_set_2.xlsx')['Label_1'].values # array type\n",
    "labels_2 = pd.read_excel('train_set_2.xlsx')['Label_2'].values # array type\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "word = vectorizer.get_feature_names()\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "# get tfidf feature matrix\n",
    "tfidf = transformer.fit_transform(X)\n",
    "\n",
    "# get LIWC feature matrix and normalize\n",
    "wb = xw.Book('train_set_2.xlsx')\n",
    "sht = wb.sheets['dataset']\n",
    "rng = sht.range('E2').expand('table')\n",
    "arr_feature = np.asarray(rng.value)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(arr_feature)\n",
    "LIWC = scaler.transform(arr_feature)\n",
    "\n",
    "# build tfidf + 3 class dataset \n",
    "X_train1, X_test1, Y_train1, Y_test1 = build_dataset(labels_2, tfidf)\n",
    "\n",
    "# build tfidf + regression dataset\n",
    "# X_train2, X_test2, Y_train2, Y_test2 = build_dataset(labels_1, tfidf)\n",
    "\n",
    "# build LIWC + 3 classes dataset \n",
    "X_train3, X_test3, Y_train3, Y_test3 = build_dataset(labels_2, LIWC)\n",
    "\n",
    "# build LIWC + regression dataset \n",
    "# X_train4, X_test4, Y_train4, Y_test4 = build_dataset(labels_1, LIWC)\n",
    "\n",
    "print(X_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# train model_1 -- tfidf + NB\n",
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train1, Y_train1.flatten())\n",
    "\n",
    "# train model_2 -- regression \n",
    "# reg1 = LinearRegression().fit(X_train2, Y_train2.flatten())\n",
    "\n",
    "# train model_3 -- LIWC + NB\n",
    "clf2 = MultinomialNB()\n",
    "clf2.fit(X_train3, Y_train3.flatten())\n",
    "\n",
    "# train model_4 -- LIWC + regression\n",
    "# reg2 = LinearRegression().fit(X_train4, Y_train4.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1 MA: 0.6505376344086021\n",
      "model_1 conf:\n",
      " [[206  60  44]\n",
      " [ 81 183  46]\n",
      " [ 58  36 216]]\n",
      "\n",
      "model_3 MA: 0.6\n",
      "model_3 conf:\n",
      " [[225  45  40]\n",
      " [107 178  25]\n",
      " [ 92  63 155]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def cal_conf(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred, labels=[-1, 0, 1])\n",
    "\n",
    "MA1 = clf1.score(X_test1, Y_test1.flatten())\n",
    "predicts1 = clf1.predict(X_test1)\n",
    "conf1 = cal_conf(Y_test1, predicts1)\n",
    "print('model_1 MA:', MA1)\n",
    "print('model_1 conf:\\n', conf1)\n",
    "\n",
    "# MSE1 = mean_squared_error(Y_test2, reg1.predict(X_test2))\n",
    "# print('\\nmodel_2 MSE:', MSE1)\n",
    "\n",
    "MA2 = clf2.score(X_test3, Y_test3.flatten())\n",
    "predicts2 = clf2.predict(X_test3)\n",
    "conf2 = cal_conf(Y_test3, predicts2)\n",
    "print('\\nmodel_3 MA:', MA2)\n",
    "print('model_3 conf:\\n', conf2)\n",
    "\n",
    "# MSE2 = mean_squared_error(Y_test4, reg2.predict(X_test4))\n",
    "# print('\\nmodel_4 MSE:', MSE2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-62eef95d0506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# X1 = np.concatenate(X_train1, X_test1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Y1 = np.concatenate(Y_train1, Y_test1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mX3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mY3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "C_range = np.logspace(-2, 5, 8)\n",
    "gamma_range = np.logspace(-5, 2, 8)\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma_range,\n",
    "                     'C': C_range},\n",
    "                    {'kernel': ['linear'], 'C': C_range}]\n",
    "score = 'accuracy'\n",
    "datasets = []\n",
    "# X1 = np.concatenate((X_train1, X_test1), axis=0)\n",
    "# Y1 = np.concatenate((Y_train1, Y_test1), axis=0)\n",
    "X3 = np.concatenate((X_train3, X_test3), axis=0)\n",
    "Y3 = np.concatenate((Y_train3, Y_test3), axis=0)\n",
    "datasets.append([X1, Y1.flatten()])\n",
    "# datasets.append([X3, Y3.flatten()])\n",
    "\n",
    "# train for dataset 1 and 3\n",
    "for dataset in datasets:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    grid = GridSearchCV(SVC(), tuned_parameters, scoring=score, n_jobs=-1, verbose=1)\n",
    "    grid.fit(dataset[0], dataset[2])\n",
    "\n",
    "    print(\"Best parameters set found on training set:\")\n",
    "    print()\n",
    "    print(grid.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = grid.cv_results_['mean_test_score']\n",
    "    stds = grid.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The scores are computed on the full test set.\")\n",
    "    print()\n",
    "    y_true, y_pred = dataset[3], grid.predict(dataset[1])\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
